{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd \"drive/MyDrive/nlp\""],"metadata":{"id":"E2TCC3iM39Pc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q -U trl transformers accelerate peft datasets bitsandbytes evaluate git+https://github.com/huggingface/huggingface_hub"],"metadata":{"id":"q_Zawfv92oAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"Xmr3WzQCy4ES"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":4,"metadata":{"jupyter":{"outputs_hidden":false},"id":"hbC9pZlGy4EX","executionInfo":{"status":"ok","timestamp":1714747058067,"user_tz":-120,"elapsed":11072,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","model_name = \"google-bert/bert-base-uncased\""]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"GfewFrCNy4EZ"},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"tjasad/Slovene_SuperGLUE_CB\")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"eU5WzY6Gy4Ea"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_jEbI9zy4Eb"},"outputs":[],"source":["id2label = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n","label2id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(id2label),\n","    id2label=id2label,\n","    label2id=label2id,\n","    trust_remote_code=True\n",")\n","model.config.use_cache = False"]},{"cell_type":"code","execution_count":8,"metadata":{"jupyter":{"outputs_hidden":false},"id":"PVdC20uCy4Ec","executionInfo":{"status":"ok","timestamp":1714747122732,"user_tz":-120,"elapsed":429,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["CONTEXT_COL = \"premise\"\n","HYPOTHESIS_COL = \"hypothesis\"\n","\n","def preprocess_function(examples):\n","    \"\"\"\n","    The preprocessing function prepares examples for processing by the model.\n","    It concatenates premise and hypothesis for each example to form a single input string.\n","    \"\"\"\n","    inputs = [f\"{premise} {hypothesis}\" for premise, hypothesis in zip(examples[CONTEXT_COL], examples[HYPOTHESIS_COL])]\n","    tokenized_examples = tokenizer(inputs, truncation=True)\n","    if \"label\" in examples:\n","        tokenized_examples[\"labels\"] = [label2id[label] for label in examples[\"label\"]]\n","    return tokenized_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"9SW79a10y4Ed"},"outputs":[],"source":["tokenized_dataset = dataset.map(preprocess_function,\n","                                remove_columns=['idx', 'premise', 'hypothesis', 'label'], batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJIffaKGy4Ee"},"outputs":[],"source":["tokenized_dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"jupyter":{"outputs_hidden":false},"id":"bBU_njk_y4Ee","executionInfo":{"status":"ok","timestamp":1714747154389,"user_tz":-120,"elapsed":12861,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":12,"metadata":{"jupyter":{"outputs_hidden":false},"id":"oqshUt8Ty4Ef","executionInfo":{"status":"ok","timestamp":1714747167587,"user_tz":-120,"elapsed":280,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","    acc = accuracy_score(labels, preds)\n","    return {\"accuracy\": acc, \"f1\": f1}"]},{"cell_type":"code","execution_count":13,"metadata":{"jupyter":{"outputs_hidden":false},"id":"dULP1dwXy4Ef","executionInfo":{"status":"ok","timestamp":1714747177552,"user_tz":-120,"elapsed":291,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from transformers import set_seed\n","\n","set_seed(42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"WUnJCl-xy4Eg"},"outputs":[],"source":["from peft import  get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n","\n","NUM_VIRTUAL_TOKENS = 12\n","\n","peft_config = PromptTuningConfig(\n","    peft_type=\"PROMPT_TUNING\",\n","    task_type=TaskType.SEQ_CLS,\n","    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n","    num_layers=6,\n","    token_dim=768,\n","    num_attention_heads=12,\n","    tokenizer_name_or_path=model_name #The pre-trained model\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"O5TnAXVry4Eg"},"outputs":[],"source":["model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":21,"metadata":{"jupyter":{"outputs_hidden":false},"id":"1t78XAkky4Eh","executionInfo":{"status":"ok","timestamp":1714748503603,"user_tz":-120,"elapsed":769,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","new_model_name = \"prompt_fine_tuned_CB_bert\"\n","\n","training_args = TrainingArguments(\n","    output_dir=new_model_name,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    learning_rate=5e-5,\n","    weight_decay=0.01,\n","    evaluation_strategy='steps',\n","    max_steps=400,\n","    use_cpu=False,\n","    load_best_model_at_end=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"Rd6tJoK5y4Eh"},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset['train'],\n","    eval_dataset=tokenized_dataset['eval'],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"LUiW-slqy4Ei"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"id":"VSBAfKZ7y4Ei","executionInfo":{"status":"ok","timestamp":1714749042880,"user_tz":-120,"elapsed":14444,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}},"outputId":"c885bea2-13cf-4984-b742-408dc3cb8d7b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [22/22 00:13]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 1.3050297498703003,\n"," 'eval_accuracy': 0.3181818181818182,\n"," 'eval_f1': 0.1536050156739812,\n"," 'eval_runtime': 14.0948,\n"," 'eval_samples_per_second': 1.561,\n"," 'eval_steps_per_second': 1.561,\n"," 'epoch': 3.6363636363636362}"]},"metadata":{},"execution_count":24}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"2VRgBfr3y4Ej"},"outputs":[],"source":["trainer.push_to_hub(new_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"UHk5mXb9y4Ej"},"outputs":[],"source":["# Example\n","hypothesis =\"Valence je pomagal\"\n","premise = \"Valence praznoglavi, Valence krepostni kreten. Zakaj si ga tip raje ni zataknil v ustrezen del lastne titanske anatomije? Je morda mislil, da mi pomaga?\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-TFTYSmIy4Ek"},"outputs":[],"source":["# We need to set the seed, otherwise some weights of the model are initialized differently every time, and consequently the result can be different each time as well\n","# set_seed(42)\n","import torch\n","\n","adapter_name = \"tjasad/\" + new_model_name\n","\n","tokenizer = AutoTokenizer.from_pretrained(adapter_name)\n","inputs = tokenizer(f\"{premise} {hypothesis}\", return_tensors=\"pt\")\n","label = torch.tensor([1]).unsqueeze(0)  # Batch size 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ie-qeEHAy4Ek"},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(id2label),\n","    id2label=id2label,\n","    label2id=label2id,\n","    trust_remote_code=True\n",")\n","outputs = model(**inputs, labels=label)\n","logits = outputs.logits"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"pJPaVBZvy4Ek"},"outputs":[],"source":["# Print prediction\n","logits.argmax().item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geaH5qify4El"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}