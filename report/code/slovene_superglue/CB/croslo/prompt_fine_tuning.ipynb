{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"E2TCC3iM39Pc"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd \"drive/MyDrive/nlp\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_Zawfv92oAE"},"outputs":[],"source":["!pip install -q -U trl transformers accelerate peft datasets bitsandbytes evaluate git+https://github.com/huggingface/huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xmr3WzQCy4ES","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11072,"status":"ok","timestamp":1714747058067,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"},"user_tz":-120},"id":"hbC9pZlGy4EX","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","model_name = \"EMBEDDIA/crosloengual-bert\""]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GfewFrCNy4EZ","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"lenatr99/Slovene_SuperGLUE_CB\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"eU5WzY6Gy4Ea","jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/orange4/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"p_jEbI9zy4Eb"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at EMBEDDIA/crosloengual-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["id2label = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n","label2id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(id2label),\n","    id2label=id2label,\n","    label2id=label2id,\n","    trust_remote_code=True\n",")\n","model.config.use_cache = False"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":429,"status":"ok","timestamp":1714747122732,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"},"user_tz":-120},"id":"PVdC20uCy4Ec","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["CONTEXT_COL = \"premise\"\n","HYPOTHESIS_COL = \"hypothesis\"\n","\n","def preprocess_function(examples):\n","    \"\"\"\n","    The preprocessing function prepares examples for processing by the model.\n","    It concatenates premise and hypothesis for each example to form a single input string.\n","    \"\"\"\n","    inputs = [f\"{premise} {hypothesis}\" for premise, hypothesis in zip(examples[CONTEXT_COL], examples[HYPOTHESIS_COL])]\n","    tokenized_examples = tokenizer(inputs, truncation=True)\n","    if \"label\" in examples:\n","        tokenized_examples[\"labels\"] = [label2id[label] for label in examples[\"label\"]]\n","    return tokenized_examples"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"9SW79a10y4Ed","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["tokenized_dataset = dataset.map(preprocess_function,\n","                                remove_columns=['idx', 'premise', 'hypothesis', 'label'], batched=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"sJIffaKGy4Ee"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 110\n","    })\n","    eval: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 22\n","    })\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12861,"status":"ok","timestamp":1714747154389,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"},"user_tz":-120},"id":"bBU_njk_y4Ee","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1714747167587,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"},"user_tz":-120},"id":"oqshUt8Ty4Ef","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","    acc = accuracy_score(labels, preds)\n","    return {\"accuracy\": acc, \"f1\": f1}"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1714747177552,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"},"user_tz":-120},"id":"dULP1dwXy4Ef","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from transformers import set_seed\n","\n","set_seed(42)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"WUnJCl-xy4Eg","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from peft import  get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n","\n","NUM_VIRTUAL_TOKENS = 12\n","\n","peft_config = PromptTuningConfig(\n","    peft_type=\"PROMPT_TUNING\",\n","    task_type=TaskType.SEQ_CLS,\n","    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n","    num_layers=6,\n","    token_dim=768,\n","    num_attention_heads=12,\n","    tokenizer_name_or_path=model_name #The pre-trained model\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"O5TnAXVry4Eg","jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 11,523 || all params: 124,148,742 || trainable%: 0.0093\n"]}],"source":["model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":769,"status":"ok","timestamp":1714748503603,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"},"user_tz":-120},"id":"1t78XAkky4Eh","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","new_model_name = \"prompt_fine_tuned_CB_croslo\"\n","\n","training_args = TrainingArguments(\n","    output_dir=new_model_name,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    logging_steps=50,\n","    evaluation_strategy='steps',\n","    max_steps=400,\n","    use_cpu=False,\n","    load_best_model_at_end=True\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Rd6tJoK5y4Eh","jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset['train'],\n","    eval_dataset=tokenized_dataset['eval'],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"LUiW-slqy4Ei","jupyter":{"outputs_hidden":false}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cce136d8ba644270be194d8eed969e78","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/400 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 1.0278, 'grad_norm': 13.051501274108887, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.45}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f050e5c7f6e4d14996bb0ae9529ae27","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.1157597303390503, 'eval_accuracy': 0.3181818181818182, 'eval_f1': 0.23064935064935063, 'eval_runtime': 2.6355, 'eval_samples_per_second': 8.348, 'eval_steps_per_second': 8.348, 'epoch': 0.45}\n","{'loss': 0.9865, 'grad_norm': 12.213147163391113, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.91}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de14d534dc6d4605adce293c675e6ac5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.1195473670959473, 'eval_accuracy': 0.36363636363636365, 'eval_f1': 0.24300699300699302, 'eval_runtime': 0.3007, 'eval_samples_per_second': 73.173, 'eval_steps_per_second': 73.173, 'epoch': 0.91}\n","{'loss': 0.8601, 'grad_norm': 11.454643249511719, 'learning_rate': 1.25e-05, 'epoch': 1.36}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74e94d2f29bf4d4e91f66afd58f58a44","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.135717511177063, 'eval_accuracy': 0.3181818181818182, 'eval_f1': 0.1536050156739812, 'eval_runtime': 0.2678, 'eval_samples_per_second': 82.141, 'eval_steps_per_second': 82.141, 'epoch': 1.36}\n","{'loss': 0.8769, 'grad_norm': 16.31204605102539, 'learning_rate': 1e-05, 'epoch': 1.82}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1998429cd6044fb1bd408dfd0d5ae743","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.1594661474227905, 'eval_accuracy': 0.3181818181818182, 'eval_f1': 0.1536050156739812, 'eval_runtime': 0.3314, 'eval_samples_per_second': 66.376, 'eval_steps_per_second': 66.376, 'epoch': 1.82}\n","{'loss': 0.9026, 'grad_norm': 9.032601356506348, 'learning_rate': 7.500000000000001e-06, 'epoch': 2.27}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c78ca4e2c0cc4e32b79335120302312f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.173268437385559, 'eval_accuracy': 0.3181818181818182, 'eval_f1': 0.1536050156739812, 'eval_runtime': 0.2728, 'eval_samples_per_second': 80.653, 'eval_steps_per_second': 80.653, 'epoch': 2.27}\n","{'loss': 0.8002, 'grad_norm': 8.974824905395508, 'learning_rate': 5e-06, 'epoch': 2.73}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1064fe549b6478dab7a29cc53170d85","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.1884652376174927, 'eval_accuracy': 0.3181818181818182, 'eval_f1': 0.1536050156739812, 'eval_runtime': 0.2949, 'eval_samples_per_second': 74.614, 'eval_steps_per_second': 74.614, 'epoch': 2.73}\n","{'loss': 0.8093, 'grad_norm': 12.539688110351562, 'learning_rate': 2.5e-06, 'epoch': 3.18}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da2594506afb43f2a5f5e1cd8380072a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.1996424198150635, 'eval_accuracy': 0.3181818181818182, 'eval_f1': 0.1536050156739812, 'eval_runtime': 0.2652, 'eval_samples_per_second': 82.941, 'eval_steps_per_second': 82.941, 'epoch': 3.18}\n","{'loss': 0.7259, 'grad_norm': 6.747017860412598, 'learning_rate': 0.0, 'epoch': 3.64}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42fb5edd0ca54039acfb4c384da16786","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.2045663595199585, 'eval_accuracy': 0.3181818181818182, 'eval_f1': 0.1536050156739812, 'eval_runtime': 0.2709, 'eval_samples_per_second': 81.217, 'eval_steps_per_second': 81.217, 'epoch': 3.64}\n","{'train_runtime': 31.3157, 'train_samples_per_second': 12.773, 'train_steps_per_second': 12.773, 'train_loss': 0.8736630058288575, 'epoch': 3.64}\n"]},{"data":{"text/plain":["TrainOutput(global_step=400, training_loss=0.8736630058288575, metrics={'train_runtime': 31.3157, 'train_samples_per_second': 12.773, 'train_steps_per_second': 12.773, 'total_flos': 15245058155940.0, 'train_loss': 0.8736630058288575, 'epoch': 3.6363636363636362})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"elapsed":14444,"status":"ok","timestamp":1714749042880,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"},"user_tz":-120},"id":"VSBAfKZ7y4Ei","outputId":"c885bea2-13cf-4984-b742-408dc3cb8d7b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fbf1d7c38ce4a3fbfbcad7ef6967808","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 1.2045663595199585,\n"," 'eval_accuracy': 0.3181818181818182,\n"," 'eval_f1': 0.1536050156739812,\n"," 'eval_runtime': 0.2783,\n"," 'eval_samples_per_second': 79.051,\n"," 'eval_steps_per_second': 79.051,\n"," 'epoch': 3.6363636363636362}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"2VRgBfr3y4Ej","jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/orange4/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4de885950c840138888b53013b76b9b","version_major":2,"version_minor":0},"text/plain":["training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56bee1ba26e24ea5af1d593170d20306","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7408a4c9dfc44ccad43fcf35e592f2f","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/lenatr99/prompt_fine_tuned_CB_croslo/commit/ce86c3599c5322ed21334990f8563844360714f0', commit_message='prompt_fine_tuned_CB_croslo', commit_description='', oid='ce86c3599c5322ed21334990f8563844360714f0', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub(new_model_name)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"UHk5mXb9y4Ej","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["# Example\n","hypothesis =\"Valence je pomagal\"\n","premise = \"Valence praznoglavi, Valence krepostni kreten. Zakaj si ga tip raje ni zataknil v ustrezen del lastne titanske anatomije? Je morda mislil, da mi pomaga?\""]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-TFTYSmIy4Ek"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9cdca32d66f4b5995e5d02a1d864ff9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51b137d7a7fb4114bd8f6670c0d3a5f8","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/329k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed7cf5a16e764288b5c37dad1a00bf15","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.11M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da3e4efc0cfc4066ac4640646a2a370f","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# We need to set the seed, otherwise some weights of the model are initialized differently every time, and consequently the result can be different each time as well\n","# set_seed(42)\n","import torch\n","\n","adapter_name = \"lenatr99/\" + new_model_name\n","\n","tokenizer = AutoTokenizer.from_pretrained(adapter_name)\n","inputs = tokenizer(f\"{premise} {hypothesis}\", return_tensors=\"pt\")\n","label = torch.tensor([1]).unsqueeze(0)  # Batch size 1"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"ie-qeEHAy4Ek"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at EMBEDDIA/crosloengual-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(id2label),\n","    id2label=id2label,\n","    label2id=label2id,\n","    trust_remote_code=True\n",")\n","outputs = model(**inputs, labels=label)\n","logits = outputs.logits"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"pJPaVBZvy4Ek","jupyter":{"outputs_hidden":false}},"outputs":[{"data":{"text/plain":["2"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Print prediction\n","logits.argmax().item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geaH5qify4El"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
