{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:45:56.667640Z",
     "start_time": "2024-05-21T17:45:56.500636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78eedc6853f148cf908417fd2c0a97bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:45:59.005637400Z",
     "start_time": "2024-05-21T17:45:56.669639200Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice, AutoTokenizer\n",
    "\n",
    "model_name = \"xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:46:03.821137Z",
     "start_time": "2024-05-21T17:45:59.006639200Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"anzeo/Slovene_SuperGLUE_COPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:46:04.808636100Z",
     "start_time": "2024-05-21T17:46:03.821637Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:46:04.813635Z",
     "start_time": "2024-05-21T17:46:04.811137Z"
    }
   },
   "outputs": [],
   "source": [
    "CONTEXT_COL = \"premise\"\n",
    "QUESTION_COL = \"question\"\n",
    "CHOICE_1_COL = \"choice1\"\n",
    "CHOICE_2_COL = \"choice2\"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    The preprocessing function needs to:\n",
    "    1. Make two copies of the CONTEXT_COL field and combine each of them with QUESTION_COL to recreate how a sentence starts.\n",
    "    2. Combine QUESTION_COL with each of the two possible choices.\n",
    "    3. Flatten these two lists so you can tokenize them, and then unflatten them afterward so each example has a corresponding input_ids, attention_mask, and labels field.\n",
    "    \"\"\"\n",
    "\n",
    "    question_headers = examples[QUESTION_COL]\n",
    "\n",
    "    # Repeat each premise two times to go with the two choice possibilities.\n",
    "    first_sentences = [[context] * 2 for context in examples[CONTEXT_COL]]\n",
    "    # Grab all choices possible for each context.\n",
    "    second_sentences = [\n",
    "        [f\"{header} {examples[choice][i]}\" for choice in [CHOICE_1_COL, CHOICE_2_COL]] for i, header\n",
    "        in enumerate(question_headers)\n",
    "    ]\n",
    "\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "\n",
    "    return {k: [v[i: i + 2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:46:04.866137Z",
     "start_time": "2024-05-21T17:46:04.814635900Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function,\n",
    "                                remove_columns=['idx', 'premise', 'question', 'choice1', 'choice2'], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:46:04.872136900Z",
     "start_time": "2024-05-21T17:46:04.869137100Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:11.193138400Z",
     "start_time": "2024-05-21T17:49:11.184636500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    label_ids = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(label_ids, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(label_ids, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:12.097137100Z",
     "start_time": "2024-05-21T17:49:11.542636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:12.100137200Z",
     "start_time": "2024-05-21T17:49:12.097636Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_alpha = 32\n",
    "lora_rank_dropout = 0.1\n",
    "lora_module_dropout = 0.0\n",
    "lora_r = 16\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    bias=\"none\",\n",
    "    base_model_name_or_path=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:13.009135700Z",
     "start_time": "2024-05-21T17:49:12.987637600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 590,593 || all params: 278,635,010 || trainable%: 0.2120\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:20.877136500Z",
     "start_time": "2024-05-21T17:49:20.834137300Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "new_model_name = \"lora_fine_tuned_copa_XLMroberta\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=new_model_name,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy='steps',\n",
    "    max_steps=400,\n",
    "    use_cpu=False,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:22.473636400Z",
     "start_time": "2024-05-21T17:49:21.911137400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:47.200279700Z",
     "start_time": "2024-05-21T17:49:25.428636300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/400 : < :, Epoch 0.02/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=400, training_loss=0.6970389080047608, metrics={'train_runtime': 21.7545, 'train_samples_per_second': 147.096, 'train_steps_per_second': 18.387, 'total_flos': 100513439953344.0, 'train_loss': 0.6970389080047608, 'epoch': 8.0})"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T17:49:47.516636400Z",
     "start_time": "2024-05-21T17:49:47.200635200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/13 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.6928784251213074,\n 'eval_accuracy': 0.59,\n 'eval_f1': 0.5883995596036432,\n 'eval_runtime': 0.304,\n 'eval_samples_per_second': 328.947,\n 'eval_steps_per_second': 42.763,\n 'epoch': 8.0}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:50:22.350136Z",
     "start_time": "2024-05-21T17:50:14.951136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "events.out.tfevents.1716313787.DESKTOP-22QTFDR.33008.3:   0%|          | 0.00/457 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dee1e0da0b00458087987dc210a8b53c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "003b64bf2ec1483b9aabde536a63888e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "events.out.tfevents.1716313765.DESKTOP-22QTFDR.33008.2:   0%|          | 0.00/9.73k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47635fba6e07440abb423bef4a95bca5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "training_args.bin:   0%|          | 0.00/5.05k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1124423813f7458fb89f700105e4e4dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "adapter_model.safetensors:   0%|          | 0.00/2.37M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "853f1bc01c744abf87d16170ea15002a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c117ced93ace441cbc71ba065e093302"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "CommitInfo(commit_url='https://huggingface.co/anzeo/lora_fine_tuned_copa_XLMroberta/commit/151e12d28c6a9a1148d940993038dc8a94e3dc2a', commit_message='lora_fine_tuned_copa_XLMroberta', commit_description='', oid='151e12d28c6a9a1148d940993038dc8a94e3dc2a', pr_url=None, pr_revision=None, pr_num=None)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:50:22.354136Z",
     "start_time": "2024-05-21T17:50:22.351137900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "choice1 = \"Naveličala sta se prepirov.\"\n",
    "choice2 = \"Izogibala sta se razgovoru o težavi.\"\n",
    "prompt = \"Odločila sta se skleniti kompromis.\"\n",
    "question = \"cause\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T17:50:28.041136500Z",
     "start_time": "2024-05-21T17:50:22.354636600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "adapter_config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71e254c9eae64604845d1cc3bd61c76a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "adapter_model.safetensors:   0%|          | 0.00/2.37M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45ee15f6076d470ba9999736412d1336"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6aa07a8699b3486f9814861ed591d9b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80a4eda05e0d41488aed133355a1e9d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0b27ea6e4cc4d6c8249ab4690f8cc99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# We need to set the seed, otherwise some weights of the model are initialized differently every time, and consequently the result can be different each time as well\n",
    "set_seed(42)\n",
    "\n",
    "adapter_name = \"anzeo/\" + new_model_name\n",
    "\n",
    "config = PeftConfig.from_pretrained(adapter_name)\n",
    "base_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "model = PeftModel.from_pretrained(base_model, adapter_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T17:50:28.162136500Z",
     "start_time": "2024-05-21T17:50:28.043138500Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer([[prompt, f\"{question} {choice1}\"], [prompt, f\"{question} {choice2}\"]], return_tensors=\"pt\",\n",
    "                   padding=True)\n",
    "labels = torch.tensor(0).unsqueeze(0)\n",
    "\n",
    "outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-21T17:50:28.167636500Z",
     "start_time": "2024-05-21T17:50:28.163136600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print prediction\n",
    "logits.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:46:44.979635100Z",
     "start_time": "2024-05-21T17:46:44.977394200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
