{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd \"drive/MyDrive/nlp\""],"metadata":{"id":"2ZVyh0zL9-bs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q -U trl transformers accelerate peft datasets bitsandbytes evaluate git+https://github.com/huggingface/huggingface_hub"],"metadata":{"id":"Z6Hx0WDl-EEh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"bDNcm2md8pml"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":4,"metadata":{"jupyter":{"outputs_hidden":false},"id":"aw5QJ3NS8pmn","executionInfo":{"status":"ok","timestamp":1715161511495,"user_tz":-120,"elapsed":4533,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from transformers import AutoModelForMultipleChoice, AutoTokenizer\n","\n","model_name = \"google-bert/bert-base-uncased\""]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"BqngQlmR8pmo"},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"tjasad/Slovene_SuperGLUE_COPA\")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"CUjh6itJ8pmo"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"jupyter":{"outputs_hidden":false},"id":"67YcI-078pmp","executionInfo":{"status":"ok","timestamp":1715161527817,"user_tz":-120,"elapsed":395,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["CONTEXT_COL = \"premise\"\n","QUESTION_COL = \"question\"\n","CHOICE_1_COL = \"choice1\"\n","CHOICE_2_COL = \"choice2\"\n","\n","\n","def preprocess_function(examples):\n","    \"\"\"\n","    The preprocessing function needs to:\n","    1. Make two copies of the CONTEXT_COL field and combine each of them with QUESTION_COL to recreate how a sentence starts.\n","    2. Combine QUESTION_COL with each of the two possible choices.\n","    3. Flatten these two lists so you can tokenize them, and then unflatten them afterward so each example has a corresponding input_ids, attention_mask, and labels field.\n","    \"\"\"\n","\n","    question_headers = examples[QUESTION_COL]\n","\n","    # Repeat each premise two times to go with the two choice possibilities.\n","    first_sentences = [[context] * 2 for context in examples[CONTEXT_COL]]\n","    # Grab all choices possible for each context.\n","    second_sentences = [\n","        [f\"{header} {examples[choice][i]}\" for choice in [CHOICE_1_COL, CHOICE_2_COL]] for i, header\n","        in enumerate(question_headers)\n","    ]\n","\n","    first_sentences = sum(first_sentences, [])\n","    second_sentences = sum(second_sentences, [])\n","\n","    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n","\n","    # Add another array to each attention mask\n","    return {k: [v[i: i + 2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"c3y33Lw58pmp"},"outputs":[],"source":["tokenized_dataset = dataset.map(preprocess_function,\n","                                remove_columns=['idx', 'premise', 'question', 'choice1', 'choice2'], batched=True)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"jupyter":{"outputs_hidden":false},"id":"0GeRit1C8pmq","executionInfo":{"status":"ok","timestamp":1715161539705,"user_tz":-120,"elapsed":422,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from dataclasses import dataclass\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","from typing import Optional, Union\n","import torch\n","\n","\n","@dataclass\n","class DataCollatorForMultipleChoice:\n","    \"\"\"\n","    Data collator that will dynamically pad the inputs for multiple choice received.\n","    \"\"\"\n","\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","\n","    def __call__(self, features):\n","        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n","        labels = [feature.pop(label_name) for feature in features]\n","        batch_size = len(features)\n","        print(\"Batch size: \", batch_size) # 1\n","        num_choices = len(features[0][\"input_ids\"])\n","        print(\"Choices num: \", num_choices) # 2\n","        flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","        flattened_features = sum(flattened_features, [])\n","\n","        batch = self.tokenizer.pad(\n","            flattened_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=\"pt\",\n","        )\n","\n","        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n","        print(\"Batch: \")\n","        print(batch)\n","\n","\n","        return batch"]},{"cell_type":"code","execution_count":10,"metadata":{"jupyter":{"outputs_hidden":false},"id":"iJjqxLuh8pmq","executionInfo":{"status":"ok","timestamp":1715161545121,"user_tz":-120,"elapsed":845,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","\n","def compute_metrics(pred):\n","    label_ids = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(label_ids, preds, average=\"weighted\")\n","    acc = accuracy_score(label_ids, preds)\n","    return {\"accuracy\": acc, \"f1\": f1}"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"ozKvxmXu8pmr"},"outputs":[],"source":["from transformers import set_seed\n","\n","set_seed(42)\n","\n","model = AutoModelForMultipleChoice.from_pretrained(model_name)\n","model.config.use_cache = False"]},{"cell_type":"code","execution_count":12,"metadata":{"jupyter":{"outputs_hidden":false},"id":"6rXxldC88pmr","executionInfo":{"status":"ok","timestamp":1715161586906,"user_tz":-120,"elapsed":1300,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from peft import  get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n","\n","NUM_VIRTUAL_TOKENS = 10\n","\n","peft_config = PromptTuningConfig(\n","    peft_type=\"PROMPT_TUNING\",\n","    task_type=TaskType.SEQ_CLS,\n","    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n","    num_layers=6,\n","    token_dim=768,\n","    num_attention_heads=12,\n","    tokenizer_name_or_path=model_name #The pre-trained model\n",")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"jupyter":{"outputs_hidden":false},"colab":{"base_uri":"https://localhost:8080/"},"id":"nbOf-wOf8pmr","executionInfo":{"status":"ok","timestamp":1715161594417,"user_tz":-120,"elapsed":461,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}},"outputId":"4f05678f-a629-402e-8308-3aab9ee72907"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 8,449 || all params: 109,491,458 || trainable%: 0.007716583699159436\n"]}],"source":["model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":14,"metadata":{"jupyter":{"outputs_hidden":false},"id":"GPbturG-8pmr","executionInfo":{"status":"ok","timestamp":1715161598132,"user_tz":-120,"elapsed":496,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}}},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","new_model_name = \"prompt_fine_tuned_copa_bert\"\n","\n","training_args = TrainingArguments(\n","    output_dir=new_model_name,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    learning_rate=3e-3,\n","    weight_decay=0.01,\n","    logging_steps=50,\n","    evaluation_strategy='steps',\n","    max_steps=400,\n","    use_cpu=False,\n","    load_best_model_at_end=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"ky5d0x9t8pms"},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset['train'],\n","    eval_dataset=tokenized_dataset['eval'],\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"jupyter":{"outputs_hidden":false},"colab":{"base_uri":"https://localhost:8080/","height":896},"id":"vDPM9iFp8pms","executionInfo":{"status":"error","timestamp":1715161607097,"user_tz":-120,"elapsed":462,"user":{"displayName":"Tjaša Domadenik","userId":"12065373928021713454"}},"outputId":"2fe69a31-f98e-4bd8-e0b0-d188b618dfc6"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"stream","name":"stdout","text":["Batch size:  1\n","Choices num:  2\n","Batch: \n","{'input_ids': tensor([[[  101, 14955, 28775,  3900, 15333, 23564,  2243,  2140,  9103,  6895,\n","           2721,  3653, 20573, 11431,  2080,  1012,   102,  3426, 26927,  6460,\n","           3669,  2061,  9808,  2819,  2140,  6460, 20909,  1012,   102],\n","         [  101, 14955, 28775,  3900, 15333, 23564,  2243,  2140,  9103,  6895,\n","           2721,  3653, 20573, 11431,  2080,  1012,   102,  3426,  1062, 19731,\n","           2615,  9033, 15333,  6728, 19506, 23296,  2050,  1012,   102]]]), 'token_type_ids': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1]]]), 'labels': tensor([0])}\n","Batch size:  1\n","Choices num:  2\n","Batch: \n","{'input_ids': tensor([[[  101,  2039,  2527, 16022,  5480,  7367, 15333,  1051,  2094, 13716,\n","           2140, 25787,  1012,   102,  3466,  7367, 12693,  5937,  2061,  3653,\n","           9153, 21661,  1012,   102],\n","         [  101,  2039,  2527, 16022,  5480,  7367, 15333,  1051,  2094, 13716,\n","           2140, 25787,  1012,   102,  3466,  7367, 12693,  5937,  7367, 15333,\n","          29250,  2884,  1012,   102]]]), 'token_type_ids': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1]]]), 'labels': tensor([1])}\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Tensors must have same number of dimensions: got 2 and 3","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3138\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;31m# concat prompt attention mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mprefix_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_virtual_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"position_ids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m70PTfsQ8pms"},"outputs":[],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"Dcrv8JP28pms"},"outputs":[],"source":["trainer.push_to_hub(new_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"AvzVgQEa8pms"},"outputs":[],"source":["# Example\n","choice1 = \"Naveličala sta se prepirov.\"\n","choice2 = \"Izogibala sta se razgovoru o težavi.\"\n","prompt = \"Odločila sta se skleniti kompromis.\"\n","question = \"cause\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDSR7LdM8pmt"},"outputs":[],"source":["# We need to set the seed, otherwise some weights of the model are initialized differently every time, and consequently the result can be different each time as well\n","set_seed(42)\n","\n","adapter_name = \"lenatr99/\" + new_model_name\n","\n","tokenizer = AutoTokenizer.from_pretrained(adapter_name)\n","inputs = tokenizer([[prompt, f\"{question} {choice1}\"], [prompt, f\"{question} {choice2}\"]], return_tensors=\"pt\",\n","                   padding=True)\n","labels = torch.tensor(0).unsqueeze(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZu0nr5N8pmt"},"outputs":[],"source":["model = AutoModelForMultipleChoice.from_pretrained(adapter_name)\n","outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n","logits = outputs.logits"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"HqqeYlD98pmt"},"outputs":[],"source":["# Print prediction\n","logits.argmax().item()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}