{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmTofaHiIQjf"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U trl transformers accelerate peft datasets bitsandbytes evaluate git+https://github.com/huggingface/huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lafyYoWEEFuB"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ktw1sP9Pp2kK"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_name = \"EMBEDDIA/sloberta\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkBT_R15KbG9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"tjasad/Slovene_SuperGLUE_BoolQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsyM-2tDPBW8"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIF3z1CpO16k"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(examples):\n",
        "\n",
        "  passage_inputs = [f\"passage : {x} \" for x in examples[\"passage\"]]\n",
        "  question_inputs = [f\"question : {x} \" for x in examples[\"question\"]]\n",
        "  inputs = [passage_input + question_input for passage_input, question_input in zip(passage_inputs, question_inputs)]\n",
        "\n",
        "  model_inputs = tokenizer(inputs, max_length=400, truncation=True)\n",
        "\n",
        "  model_inputs[\"labels\"] = examples[\"label\"]\n",
        "  model_inputs[\"labels\"] = [int(label) for label in model_inputs[\"labels\"]]\n",
        "\n",
        "  return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_data, remove_columns=['idx', 'passage', 'label', 'question'], batched=True)\n",
        "\n",
        "tokenized_train = tokenized_dataset[\"train\"]\n",
        "tokenized_val = tokenized_dataset[\"eval\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZHJlsvwaXcsk"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jqWuCr2wZLWz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEn2N7bAa1iO"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"False\", 1: \"True\"}\n",
        "label2id = {\"False\": 0, \"True\": 1}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9hYgVLI0MoJr"
      },
      "outputs": [],
      "source": [
        "from peft import  get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
        "\n",
        "NUM_VIRTUAL_TOKENS = 12\n",
        "\n",
        "peft_config = PromptTuningConfig(\n",
        "    peft_type=\"PROMPT_TUNING\",\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n",
        "    num_layers=6,\n",
        "    token_dim=768,\n",
        "    num_attention_heads=12,\n",
        "    tokenizer_name_or_path=model_name #The pre-trained model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmAz3x1TNbGn"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "print(model.print_trainable_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UNki-q3mOdd9"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "new_model_name = \"prompt_fine_tuned_boolq_sloberta\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=new_model_name,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy='steps',\n",
        "    max_steps=400,\n",
        "    use_cpu=False,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPNgC-OhgY_4"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "sk9xEr6VY1U4",
        "outputId": "20130241-a653-4eda-e036-d2fffc41c55f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 00:51, Epoch 33/34]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.661600</td>\n",
              "      <td>0.586901</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.642700</td>\n",
              "      <td>0.574569</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.636500</td>\n",
              "      <td>0.570392</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.640700</td>\n",
              "      <td>0.567498</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.635200</td>\n",
              "      <td>0.565808</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.638600</td>\n",
              "      <td>0.564095</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>0.564257</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.636300</td>\n",
              "      <td>0.564054</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=0.642004919052124, metrics={'train_runtime': 53.1596, 'train_samples_per_second': 60.196, 'train_steps_per_second': 7.525, 'total_flos': 399574581930720.0, 'train_loss': 0.642004919052124, 'epoch': 33.333333333333336})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgiWPuVjZC1o"
      },
      "outputs": [],
      "source": [
        "# save model to hub\n",
        "model_location = \"tjasad\" + new_model_name\n",
        "trainer.push_to_hub(model_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "xe9M0y9Fnrb5",
        "outputId": "a3adb30b-cbb0-4dcf-d74b-367504377fa0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5640535354614258,\n",
              " 'eval_accuracy': 0.7777777777777778,\n",
              " 'eval_f1': 0.6805555555555557,\n",
              " 'eval_runtime': 0.169,\n",
              " 'eval_samples_per_second': 106.481,\n",
              " 'eval_steps_per_second': 17.747,\n",
              " 'epoch': 33.333333333333336}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g09CAhB5WuF4"
      },
      "outputs": [],
      "source": [
        "# Example\n",
        "text=\"passage : Bankovec za 20 evrov – Zaenkrat obstaja le ena celotna serija evrskih bankovcev, vendar pa izhaja nova serija, ki bo podobna sedanji. Evropska centralna banka bo pravočasno naznanila, kdaj bodo bankovci iz prve serije izgubili status zakonitega plačilnega sredstva. question : Ali je bankovec za 20 evrov iz prve serije še vedno zakonito plačilno sredstvo?\"\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model='tjasad/prompt_fine_tuned_boolq')\n",
        "classifier(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkO2N77-5z8X"
      },
      "outputs": [],
      "source": [
        "# GPU RAM = 2.1 GB"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
