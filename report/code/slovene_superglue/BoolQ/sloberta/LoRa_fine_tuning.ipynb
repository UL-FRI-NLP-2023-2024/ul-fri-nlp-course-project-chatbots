{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9V_UnRwMEhF"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U trl transformers accelerate peft datasets bitsandbytes evaluate git+https://github.com/huggingface/huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htPpLUrXIQY4",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3M27GwEMIQY6",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"EMBEDDIA/sloberta\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnCmBWCzIQY7",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"tjasad/Slovene_SuperGLUE_BoolQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRlxdUPDIQY8",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C4y0W2fsIQY8"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(examples):\n",
        "    passage_inputs = [f\"passage : {x} \" for x in examples[\"passage\"]]\n",
        "    question_inputs = [f\"question : {x} \" for x in examples[\"question\"]]\n",
        "    inputs = [passage_input + question_input for passage_input, question_input in zip(passage_inputs, question_inputs)]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=400, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = examples[\"label\"]\n",
        "    model_inputs[\"labels\"] = [int(label) for label in model_inputs[\"labels\"]]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly-HpeBDIQY8"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(preprocess_data, remove_columns=['idx', 'passage', 'label', 'question'], batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MQHJm_K9IQY9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XuwQcpDAIQY9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    label_ids = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(label_ids, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwJ5X-7qIQY9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, set_seed\n",
        "\n",
        "\n",
        "id2label = {0: \"False\", 1: \"True\"}\n",
        "label2id = {\"False\": 0, \"True\": 1}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Q1r-9Zf_IQY9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType, PeftType\n",
        "\n",
        "lora_alpha = 32\n",
        "lora_r = 16\n",
        "target_modules = [\"attention.self.query\", \"attention.self.value\"]\n",
        "\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    peft_type = PeftType.LORA,\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    bias=\"none\",\n",
        "    base_model_name_or_path=model_name,\n",
        "    target_modules=target_modules,\n",
        "    inference_mode=False,\n",
        "    lora_dropout=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFU0-yVcIQY9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VQ_FI2c4IQY-",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "\n",
        "new_model_name = \"lora_fine_tuned_boolq_sloberta\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=new_model_name,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy='steps',\n",
        "    max_steps=400,\n",
        "    use_cpu=False,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYsXIl2YIQY-",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['eval'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "3TupQlsxIQY-",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "fa260884-a413-42b5-abac-ee5a48b5f075"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 00:53, Epoch 33/34]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.676700</td>\n",
              "      <td>0.582285</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.654800</td>\n",
              "      <td>0.567579</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.654000</td>\n",
              "      <td>0.568792</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.654500</td>\n",
              "      <td>0.571801</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.652100</td>\n",
              "      <td>0.568770</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.650700</td>\n",
              "      <td>0.565437</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.649400</td>\n",
              "      <td>0.565843</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.646000</td>\n",
              "      <td>0.564764</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.680556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=0.6547855854034423, metrics={'train_runtime': 54.5903, 'train_samples_per_second': 58.618, 'train_steps_per_second': 7.327, 'total_flos': 402307396954848.0, 'train_loss': 0.6547855854034423, 'epoch': 33.333333333333336})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "5RoU18tBIQY-",
        "outputId": "1dc7bf15-13f5-4279-b19f-66a322738043"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5647640228271484,\n",
              " 'eval_accuracy': 0.7777777777777778,\n",
              " 'eval_f1': 0.6805555555555557,\n",
              " 'eval_runtime': 0.1714,\n",
              " 'eval_samples_per_second': 105.015,\n",
              " 'eval_steps_per_second': 17.503,\n",
              " 'epoch': 33.333333333333336}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SibVxzT9IQY-",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(new_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZC-aVd5IQY_",
        "outputId": "a334bba6-693c-41fe-d4a5-5ffa7fd40d5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at EMBEDDIA/sloberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'LABEL_1', 'score': 0.5613789558410645}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "adapter_name = \"tjasad/\" + new_model_name\n",
        "\n",
        "# Example\n",
        "text=\"passage : Bankovec za 20 evrov – Zaenkrat obstaja le ena celotna serija evrskih bankovcev, vendar pa izhaja nova serija, ki bo podobna sedanji. Evropska centralna banka bo pravočasno naznanila, kdaj bodo bankovci iz prve serije izgubili status zakonitega plačilnega sredstva. question : Ali je bankovec za 20 evrov iz prve serije še vedno zakonito plačilno sredstvo?\"\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=adapter_name)\n",
        "classifier(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bje3HfryIQY_"
      },
      "outputs": [],
      "source": [
        "# GPU RAM = 3.2 GB"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
